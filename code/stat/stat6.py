# y-2x+3 그래프 그리기
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

# y=2x+3을 기반으로 데이터를 생성하고 일부 랜덤 샘플을 선택하여 시각화

# x값의 범위 설정
x=np.linspace(0, 100, 400)

# y 값 계산
y=2*x+3

# x값의 범위 및 데이터 샘플링
# obs_x는 𝑦=2𝑥+3 직선과 함꼐 랜덤하게 선택된 20개의 집 크기, 임의로 선택된 집 크기
obs_x=np.random.choice(np.arange(100), 20)

# 오차항 생성 및 y 값 계산
# epsilon은 실제 데이터에서 관찰될 수 있는 불규칙한 변동을 모델링하기 위해 추가된 오차항
epsilon_i=norm.rvs(loc=0, scale=10, size=20) # 평균 0, 표준편차 10인 정규분포를 따르는 난수 20개 생성
obs_y=2*obs_x+3 +epsilon_i 
# obs_y는 obs_x에 대한 선형 함수 𝑦=2𝑥+3에 epsilon_i를 더해 계산된 값, 실제 관측된 y 값을 나타냄
# obs_y는 obs_x와 대응하는 y 값들이 오차항에 의해 변동된 모습을 보여줌

# 그래프 그리기
plt.plot(x, y, label='y=2x+3', color='black')
plt.scatter(obs_x, obs_y, color='blue', s=3)
plt.show()
plt.clf()

# 오차항을 넣는 이유는 실제 데이터가 모델에 의해 예측된 값과 항상 일치하지 않기 때문
# 다양한 요인들이 존재하기 때문에 실제 관측된 값(obs_y)은
# 단순한 선형 모델(y = 2x + 3)로 설명되지 않는 부분이 있습니다. 이 부분이 바로 오차항
==============================================================================================

# 선형 회귀 모델 생성
model = LinearRegression()

# 모델 학습
obs_x=obs_x.reshape(-1, 1)
model.fit(obs_x, obs_y)

# 회귀 직선의 기울기와 절편
model.coef_ # 기울기 a hat
model.intercept_ # 절편 b hat

# 회귀 직선 그리기
x=np.linspace(0, 100, 400)
y=model.coef_[0]*x+model.intercept_
plt.xlim([0, 100])
plt.ylim(0, 300)
plt.plot(x, y, color='red') # 회귀직선
plt.show()
plt.clf()

import statsmodels.api as sm
obs_x=sm.add_constant(obs_x)
model =sm.OLS(obs_y, obs_x).fit()
print(model.summary())

==============================================================================================
# 주어진 사실: sigma=8.79
# H0: Mu=10
# H1: Mu!=10
# x-bar=18이라고 했을 때
# 표준편차: sigma/np.sqrt(20) = 1.96
# 1-norm.cdf(18, loc=10, scale=1.96) = 0.000001 (유의확률)
# -> H0 기각

# H1:M>M0인 경우 P(T>=t)
# ex. H0: M<=14, H1: M>14
# 
# H1:M!=M0인 경우 2P(T>=np.abs(t))
# ex. H0: M=14, H1: M!=14
# 
# 양측검정이라면 1-(norm.cdf(18, loc=10, scale=1.96)*2)
# 
# N(10, 1.96^2)
# P(X>=18)
# 표준화 X-Mu/sigma -> 18-10/1.96=4.08
# 1-norm.cdf(4.08, loc=o, scale=1)
# 
# - x1, x2, .. , xn 모표준편차
# 귀무가설 vs 대립가설 설정
# 1. z=X-bar-Mu0/(sigma/np.sqrt(n)) 계산
# 2. 주어진 z로 유의확률계산 (표본정규분포로 활용)
# 3. 유의수준과 비교해서 귀무가설 기각할지 말지 결정
# 
# - 모표준편차 모를 때
# 귀무가설 vs 대립가설 설정
# 1. t=x_bar-Mu0/(s/np.sqrt(n)) 계산
# 2. 주어진 t로 유의확률 계산 (t분포 n-1 활용)
# 3. 유의수준과 비교해서 귀무가설 기각할지 말지 결정

==============================================================================================
# 귀무가설 ( 𝐻0 : Null Hypothesis )
# 귀무가설은 기본적으로 전제가 되는 가정 혹은 기존에 참이라고 받아들여지고 있는 가정입니다.
# 𝐻0 ∶ 𝜇(모평균) = 𝜇0 (귀무가설이 주장하는 평균값)
# • 귀무가설은 위와 같이 항상 등호(=) 형식을 띄고 있습니다. 꼭 기억해 주세요!
# • 귀무가설을 말로 표현 할 때, 보통 ‘0과 같다’, ‘차이가 없다’, 혹은 ‘효과가 없다’ 라고 하는 형태를
# 많이 띕니다. (Null의 의미)

# 대립가설 ( 𝐻1 : Alternative Hypothesis )
# 대립가설은 현재까지 받아들여지고 있는 귀무가설과 대립되는 가설입니다. 따라서, 대립가설을 받아
# 들이기 위해서는 확실한 증거 필요합니다.
# • 귀무가설의 반대 상황을 나타냅니다.
# • 귀무가설이 기각 되었을 때 받아들여지게 된다.

# 대립가설 예
# 𝐻𝐴 ∶ 𝜇 ≠ 3 양측검정(two‑tailed test)
# 𝐻𝐴 ∶ 𝜇 < 3, 𝐻𝐴 ∶ 𝜇 > 3 단측검정(one‑tailed test)

# 유의 확률 (p‑value)
# 귀무가설이 참이라는 가정하에서 검정통계량 값이 주어진 관측값과 같거나, 더 극단적인 값을 얻게
# 될 확률.  아래 그림의 어두운 부분에 해당하는 확률값이 양측 검정에서의 p‑value를 표현한 것

# - 양측 검정의 대립가설 형태는 양쪽을 모두 고려합니다.
# 𝐻𝑎 ∶ 𝜇 ≠ 𝜇0 인 경우 2𝑃 (𝑇 ≥ |𝑡|)
# - 단측검정의 대립가설 형태는 한쪽 만을 고려합니다.
# 𝐻𝑎 ∶ 𝜇 > 𝜇0 인 경우 𝑃 (𝑇 ≥ 𝑡), 𝐻𝑎 ∶ 𝜇 < 𝜇0 인 경우 𝑃 (𝑇 ≤ 𝑡)

==============================================================================================
# ADP p. 57

# Q2
H0(귀무가설) Mu >= 16 vs HA(대립가설) Mu < 16

# Q3 검정통계량
# 검정통계량 값 계산 t 검정 통계량 값
x= np.array([15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927,
15.382, 16.709, 16.804])
t_value=(np.mean(x)-16)/(np.std(x, ddof=1)/np.sqrt(15))
t_value

# Q4 p‑value
from scipy.stats import t
p_value = t.cdf(t_value, df=14)
p_value

# Q6. 현대자동차의 신형 모델의 평균 복합 에너지 소비효율에 대하여 95% 신뢰구간을 구해보세요.
Cl_1 = np.mean(x) - t.ppf(0.975, df = 14) * (np.std(x, ddof=1))/np.sqrt(15)
Cl_2 = np.mean(x) + t.ppf(0.975, df = 14) * (np.std(x, ddof=1))/np.sqrt(15)
